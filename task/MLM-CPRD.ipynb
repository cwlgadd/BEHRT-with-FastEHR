{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEHRT MLM with new data\n",
    "\n",
    "```This is a modified version of the MLM.ipynb notebook```\n",
    "\n",
    "This notebook has been changed to run new benchmarking datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"local_example\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added path '/rds/homes/g/gaddcz/Projects/BEHRT-with-FastEHR/my-virtual-env-icelake/lib/python3.10/site-packages' at start of search paths.\n",
      "/rds/homes/g/gaddcz/Projects/BEHRT-with-FastEHR/task\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "node_type = os.getenv('BB_CPU')\n",
    "venv_dir = f'/rds/homes/g/gaddcz/Projects/BEHRT-with-FastEHR/my-virtual-env-{node_type}'\n",
    "venv_site_pkgs = Path(venv_dir) / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'\n",
    "if venv_site_pkgs.exists():\n",
    "    sys.path.insert(0, str(venv_site_pkgs))\n",
    "    print(f\"Added path '{venv_site_pkgs}' at start of search paths.\")\n",
    "else:\n",
    "    print(f\"Path '{venv_site_pkgs}' not found. Check that it exists and/or that it exists for node-type '{node_type}'.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.common import create_folder\n",
    "from common.pytorch import load_model\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from model.utils import age_vocab\n",
    "from common.common import load_obj\n",
    "from dataLoader.MLM import MLMLoader\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from model.MLM import BertForMaskedLM\n",
    "from model.optimiser import adam\n",
    "import sklearn.metrics as skm\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embedding'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        \n",
    "class TrainConfig(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide which dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_example\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match dataset:\n",
    "    case \"local_example\":\n",
    "        file_config = {\n",
    "            'vocab':'data/local_example/token2idx',  # vocabulary idx2token, token2idx\n",
    "            'data': 'data/local_example/data_train.parquet',  # formated data \n",
    "            'model_path': f'data/{dataset}/', # where to save model\n",
    "            'model_name': 'local_MLM-notebook.ckpt', # model name\\\n",
    "            'file_name': 'local_MLM-notebook.out',  # log path\n",
    "        }\n",
    "    case \"fastehr_example\":\n",
    "        file_config = {\n",
    "            'vocab':'/rds/homes/g/gaddcz/Projects/FastEHR/examples/data/_built/adapted/BEHRT/T2D_hypertension/token2idx',  # vocabulary idx2token, token2idx\n",
    "            'data': '/rds/homes/g/gaddcz/Projects/FastEHR/examples/data/_built/adapted/BEHRT/T2D_hypertension/dataset.parquet',  # formated data \n",
    "            'model_path': f'data/{dataset}/', # where to save model\n",
    "            'model_name': 'fastehr_MLM-notebook.ckpt', # model name\\\n",
    "            'file_name': 'fastehr_MLM-notebook.out',  # log path\n",
    "        }\n",
    "    case \"hypertension\":\n",
    "        file_config = {\n",
    "            'vocab':'/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/BEHRT/token2idx',  # vocabulary idx2token, token2idx\n",
    "            'data': '/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_Hypertension/BEHRT/train_dataset.parquet',  # formated data \n",
    "            'model_path': f'data/{dataset}/', # where to save model\n",
    "            'model_name': 'hypertension_MLM-notebook.ckpt', # model name\\\n",
    "            'file_name': 'hypertension_MLM-notebook.out',  # log path\n",
    "        }\n",
    "    case \"cvd\":\n",
    "        file_config = {\n",
    "            'vocab':'/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/BEHRT/token2idx',  # vocabulary idx2token, token2idx\n",
    "            'data': '/rds/projects/g/gokhalkm-optimal/OPTIMAL_MASTER_DATASET/data/FoundationalModel/FineTune_CVD/BEHRT/train_dataset.parquet',  # formated data \n",
    "            'model_path': f'data/{dataset}/', # where to save model\n",
    "            'model_name': 'cvd_MLM-notebook.ckpt', # model name\\\n",
    "            'file_name': 'cvd_MLM-notebook.out',  # log path\n",
    "        }\n",
    "    \n",
    "    case _:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "create_folder(file_config['model_path'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    'max_seq_len': 64,\n",
    "    'max_age': 110,\n",
    "    'month': 1,\n",
    "    'age_symbol': None,\n",
    "    'min_visit': 1,                        # Reduced to one (from 5) to be comparable\n",
    "    'gradient_accumulation_steps': 1\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 256,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'device': 'cuda:0'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertVocab = load_obj(file_config['vocab'])\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], mon=global_params['month'], symbol=global_params['age_symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(file_config['data'])\n",
    "# remove patients with visits less than min visit\n",
    "data['length'] = data['caliber_id'].apply(lambda x: len([i for i in range(len(x)) if x[i] == 'SEP']))\n",
    "data = data[data['length'] >= global_params['min_visit']]\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dset = MLMLoader(data, BertVocab['token2idx'], ageVocab, max_len=train_params['max_len_seq'], code='caliber_id')\n",
    "trainload = DataLoader(dataset=Dset, batch_size=train_params['batch_size'], shuffle=True, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()), # number of disease + symbols for word embedding\n",
    "    'hidden_size': 288, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(ageVocab.keys()), # number of vocab for age embedding\n",
    "    'max_position_embedding': train_params['max_len_seq'], # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.1, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 12, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.1, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = BertConfig(model_config)\n",
    "model = BertForMaskedLM(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "model = model.to(train_params['device'])\n",
    "optim = adam(params=list(model.named_parameters()), config=optim_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model using BEHRT's experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(label, pred):\n",
    "    logs = nn.LogSoftmax()\n",
    "    label=label.cpu().numpy()\n",
    "    ind = np.where(label!=-1)[0]\n",
    "    truepred = pred.detach().cpu().numpy()\n",
    "    truepred = truepred[ind]\n",
    "    truelabel = label[ind]\n",
    "    truepred = logs(torch.tensor(truepred))\n",
    "    outs = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
    "    precision = skm.precision_score(truelabel, outs, average='micro')\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e, loader):\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt= 0\n",
    "    start = time.time()\n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        cnt +=1\n",
    "        batch = tuple(t.to(train_params['device']) for t in batch)\n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, masked_label = batch\n",
    "        loss, pred, label = model(input_ids, age_ids, segment_ids, posi_ids,attention_mask=attMask, masked_lm_labels=masked_label)\n",
    "        if global_params['gradient_accumulation_steps'] >1:\n",
    "            loss = loss/global_params['gradient_accumulation_steps']\n",
    "        loss.backward()\n",
    "        \n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "        \n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        if step % 200==0:\n",
    "            print(\"epoch: {}\\t| cnt: {}\\t|Loss: {}\\t| precision: {:.4f}\\t| time: {:.2f}\".format(e, cnt, temp_loss/2000, cal_acc(label, pred), time.time()-start))\n",
    "            temp_loss = 0\n",
    "            start = time.time()\n",
    "            \n",
    "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "    create_folder(file_config['model_path'])\n",
    "    output_model_file = os.path.join(file_config['model_path'], file_config['model_name'])\n",
    "\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        \n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n",
      "/rds/homes/g/gaddcz/Projects/BEHRT-with-FastEHR/my-virtual-env-icelake/lib/python3.10/site-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| cnt: 1\t|Loss: 0.0012827775478363038\t| precision: 0.0057\t| time: 1.49\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\t| cnt: 1\t|Loss: 0.000769543170928955\t| precision: 0.4615\t| time: 0.38\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\t| cnt: 1\t|Loss: 0.0006995547413825989\t| precision: 0.4871\t| time: 0.32\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\t| cnt: 1\t|Loss: 0.0006977683901786805\t| precision: 0.5125\t| time: 0.36\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\t| cnt: 1\t|Loss: 0.0006403416395187378\t| precision: 0.5222\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\t| cnt: 1\t|Loss: 0.0006386865377426147\t| precision: 0.5067\t| time: 0.36\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\t| cnt: 1\t|Loss: 0.0006288836002349853\t| precision: 0.4964\t| time: 0.33\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\t| cnt: 1\t|Loss: 0.0005998504161834717\t| precision: 0.5248\t| time: 0.35\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\t| cnt: 1\t|Loss: 0.0005783680677413941\t| precision: 0.5709\t| time: 0.35\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\t| cnt: 1\t|Loss: 0.0006060991883277893\t| precision: 0.5017\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\t| cnt: 1\t|Loss: 0.0006409665942192078\t| precision: 0.5180\t| time: 0.36\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11\t| cnt: 1\t|Loss: 0.0005791863799095154\t| precision: 0.5798\t| time: 0.41\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12\t| cnt: 1\t|Loss: 0.0006020164489746094\t| precision: 0.5213\t| time: 0.35\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13\t| cnt: 1\t|Loss: 0.0006534802317619324\t| precision: 0.4695\t| time: 0.37\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14\t| cnt: 1\t|Loss: 0.0005927158594131469\t| precision: 0.5576\t| time: 0.31\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15\t| cnt: 1\t|Loss: 0.0005723985433578492\t| precision: 0.5594\t| time: 0.35\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16\t| cnt: 1\t|Loss: 0.0006252151131629944\t| precision: 0.5167\t| time: 0.35\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17\t| cnt: 1\t|Loss: 0.0006041809320449829\t| precision: 0.5152\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18\t| cnt: 1\t|Loss: 0.0005607065558433532\t| precision: 0.5461\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19\t| cnt: 1\t|Loss: 0.0005538775324821472\t| precision: 0.5318\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20\t| cnt: 1\t|Loss: 0.0006020679473876953\t| precision: 0.5215\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21\t| cnt: 1\t|Loss: 0.0005866385102272034\t| precision: 0.5258\t| time: 0.35\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22\t| cnt: 1\t|Loss: 0.0005903868675231934\t| precision: 0.5310\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23\t| cnt: 1\t|Loss: 0.0005873569250106811\t| precision: 0.5385\t| time: 0.37\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24\t| cnt: 1\t|Loss: 0.0006153668165206909\t| precision: 0.5361\t| time: 0.33\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25\t| cnt: 1\t|Loss: 0.0005415284633636475\t| precision: 0.5382\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26\t| cnt: 1\t|Loss: 0.0005852963924407959\t| precision: 0.5364\t| time: 0.33\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27\t| cnt: 1\t|Loss: 0.0006130174398422242\t| precision: 0.4966\t| time: 0.36\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28\t| cnt: 1\t|Loss: 0.0005821158289909362\t| precision: 0.5256\t| time: 0.33\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29\t| cnt: 1\t|Loss: 0.0005855637192726136\t| precision: 0.5051\t| time: 0.36\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30\t| cnt: 1\t|Loss: 0.0005689348578453064\t| precision: 0.5276\t| time: 0.32\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31\t| cnt: 1\t|Loss: 0.0005971667766571045\t| precision: 0.5417\t| time: 0.37\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32\t| cnt: 1\t|Loss: 0.0005990300178527832\t| precision: 0.5343\t| time: 0.37\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33\t| cnt: 1\t|Loss: 0.0005350791215896607\t| precision: 0.5580\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34\t| cnt: 1\t|Loss: 0.0005607466697692871\t| precision: 0.5199\t| time: 0.48\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35\t| cnt: 1\t|Loss: 0.0005318915843963623\t| precision: 0.5696\t| time: 0.46\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36\t| cnt: 1\t|Loss: 0.0006212589740753173\t| precision: 0.4982\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37\t| cnt: 1\t|Loss: 0.00053653484582901\t| precision: 0.5493\t| time: 0.33\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38\t| cnt: 1\t|Loss: 0.0005994047522544861\t| precision: 0.5697\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39\t| cnt: 1\t|Loss: 0.0006321800947189331\t| precision: 0.5153\t| time: 0.37\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40\t| cnt: 1\t|Loss: 0.0005846552848815918\t| precision: 0.5475\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41\t| cnt: 1\t|Loss: 0.0005630881190299987\t| precision: 0.5618\t| time: 0.32\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42\t| cnt: 1\t|Loss: 0.000582395851612091\t| precision: 0.5150\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43\t| cnt: 1\t|Loss: 0.0005837717056274414\t| precision: 0.5222\t| time: 0.36\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44\t| cnt: 1\t|Loss: 0.0006117733120918273\t| precision: 0.5229\t| time: 0.32\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45\t| cnt: 1\t|Loss: 0.0005559228062629699\t| precision: 0.5724\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46\t| cnt: 1\t|Loss: 0.0006410897374153137\t| precision: 0.4904\t| time: 0.33\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47\t| cnt: 1\t|Loss: 0.00056022047996521\t| precision: 0.5277\t| time: 0.37\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48\t| cnt: 1\t|Loss: 0.0005666314959526062\t| precision: 0.5316\t| time: 0.35\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240254/589800408.py:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  truepred = logs(torch.tensor(truepred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49\t| cnt: 1\t|Loss: 0.0005858151316642761\t| precision: 0.5366\t| time: 0.34\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    }
   ],
   "source": [
    "data_len = 1000\n",
    "\n",
    "f = open(os.path.join(file_config['model_path'], file_config['file_name']), \"w\")\n",
    "f.write('{}\\t{}\\t{}\\n'.format('epoch', 'loss', 'time'))\n",
    "for e in range(50):\n",
    "    loss, time_cost = train(e, trainload)\n",
    "    loss = loss/data_len\n",
    "    f.write('{}\\t{}\\t{}\\n'.format(e, loss, time_cost))\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "sys_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
